# 散度

## KL (Kullback-Leibler) Divergence

KL散度又称相对熵，为信息散度（增益），是两个概率分布P和Q之间差别的非对称的度量，即度量使用基于Q的编码方式对P进行编码所需的额外bits数，P表示数据的真实分布，则Q表示P的近似分布。
$$
D_{KL}(P\|Q)=\sum_{x\in X}P(x)\log\frac1{Q(x)}-\sum_{x\in X}P(x)\log\frac1{P(x)}=\sum_{x\in X}P(x)\log\frac{P(x)}{Q(x)}
$$
KL散度性质：

- 不对称性；
- 为非负值，因为对数函数为凸函数；
- 不满足三角不等式。

KL散度局限性：

当两个分布距离很远，完全没有重叠时，KL散度值失去意义。

单变量高斯分布概率密度：
$$
N(x|μ,σ^2)=\frac{1}{\sqrt{2πσ^2}}e^{−\frac{1}{2σ^2}(x−μ)^2}
$$
多变量高斯分布概率密度，其中Σ为协方差矩阵：
$$
N(x|μ,Σ)=\frac{1}{(2π)^{n/2}|Σ|^{1/2}}e^{−\frac{1}{2}(x−μ)^TΣ^{−1}(x−μ)}
$$


## JS (Jensen-Shannon) Divergence

JS散度是基于KL散度的变形，度量两个概率分布的相似度，解决了KL散度非对称的问题，一般是对称的，取值在0到1之间。
$$
D_{JS}(P‖Q)=\frac{1}{2}D_{KL}(P‖\frac{P+Q}{2})+\frac{1}{2}D_{KL}(Q‖\frac{P+Q}{2})
$$
JS散度性质：

- 对称性

JS散度局限性：

当两个分布距离很远，完全没有重叠时，JS散度为一个常数，在学习算法中也就意味着这一点的梯度为0，即梯度消失。

## TV(Total Variation)Divergence

TV散度是另一种用于衡量概率分布之间差异的指标，定义为：
$$
D_{TV}(P,Q)=\frac{1}{2}\sum_x|P(x)−Q(x)|
$$
TV散度的特点包括：

- 对称性
- 取值范围：其值在0到1之间，0表示完全相同，1表示完全不同。

## TV散度与KL散度的比较

| 特性     | KL散度                   | TV散度                     |
| -------- | ------------------------ | -------------------------- |
| 对称性   | 非对称                   | 对称                       |
| 取值范围 | 从0到无穷大              | 从0到1                     |
| 性质     | 不满足三角不等式         | 满足三角不等式             |
| 适用场景 | 适用于信息理论和统计推断 | 适用于概率分布的相似性评估 |