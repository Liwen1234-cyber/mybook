# 矩阵

## 矩阵的乘积

### 矩阵相乘的理解

矩阵是线性空间中的线性变换的一个描述。在一个线性空间中，只要我们选定一组基，那么对于任何一个线性变换，都能够用一个确定的矩阵来加以描述

左乘矩阵是进行行操作，右乘矩阵是进行列操作。

$\boldsymbol{C} = \boldsymbol{A}\times\boldsymbol{B}$中的$\boldsymbol{B}$的列向量可以看作是以$\boldsymbol{A}$的列向量为基的子空间坐标。

### Hadamard哈达玛积(矩阵点乘)(Hadamard Product)

哈达玛积就是两个矩阵**对应位置的元素**相乘，布局不变。俗称**矩阵点乘**，符号是空心圆 ∘，两个矩阵的形状必须一样。

### 矩阵内积 (Iner Product of Matrices)

符号：⟨ . , . ⟩
目的：度量长度。
定义：列向量$\boldsymbol{a}$与行向量$\boldsymbol{b}$的内积是指：组成$\boldsymbol{a}的第$一个元素与组成$\boldsymbol{b}$的第一个元素的乘积，依次，m个这样的乘积的加和。例如，
$$
<\boldsymbol{a}，\boldsymbol{b}>=a_{1}b_{1}+a_{2}b_{2}
$$

矩阵$\boldsymbol{A}$与矩阵$\boldsymbol{B}$的内积是指：组成$\boldsymbol{A}$的第一个向量与组成$\boldsymbol{B}$的第一个向量的内积，依次，m个这样的内积的加和。
$$
<\boldsymbol{A}，\boldsymbol{B}>=\sum^n_{i=1}\sum^n_{j=1}a_{ij}*b_{ij}
$$

### 克罗内克积（Kronecker Product ）

符号：⊗
LaTex: $\otimes$
定义：克罗内克积是两个任意大小的矩阵间的运算，它是张量积的特殊形式。给定$\boldsymbol{A}$和$\boldsymbol{B}$，则$\boldsymbol{A}$和$\boldsymbol{B}$的克罗内克积是一个在空间$\mathbb{R}^{\mathrm{mp}\times\mathrm{nq}}$的分块矩阵：
$$
\left.A\otimes B=\left[\begin{array}{ccc}\mathrm{a}_{11}B&\cdots&\mathrm{a}_{1\mathrm{n}}B\\ \vdots&\ddots&\vdots\\ \mathrm{a}_{\mathrm{m}1}B&\cdots&\mathrm{a}_{\mathrm{mn}}B\end{array}\right.\right]
$$

## 矩阵求导

### 实值函数相对于实向量的梯度

相对于$n×1$向量$x$的梯度算子记作$∇x$,定义为：
$$
\nabla_{\boldsymbol{x}}=\left[\frac\partial{\partial x_1},\frac\partial{\partial x_2},\ldots,\frac\partial{\partial x_n}\right]^T=\frac\partial{\partial\boldsymbol{x}}
$$
因此,$n×1$实向量$x$为变元的实标量函数$f(\boldsymbol{x})$相对于x的梯度为$n×1$的列向量，定义为：
$$
\nabla _ \boldsymbol{x} f(\boldsymbol{x})=\left[\frac{\partial f(\boldsymbol{x})}{\partial x_1},\frac{\partial f(\boldsymbol{x})}{\partial x_2},\cdots,\frac{\partial f(\boldsymbol{x})}{\partial x_n} \right]^T=\frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}}
$$
梯度方向的负方向成为变元$\boldsymbol{x}$的梯度流(gradient flow)，记为：
$$
\dot{\boldsymbol{x}}=-\nabla_{{\boldsymbol{x}}}f(\boldsymbol{x})
$$
从梯度的定义式可以看出：

1. 一个以向量为变元的变量函数的梯度为一向量。
2. 梯度的每个分量给出了变量函数在该分量方向上的变化率

梯度向量最重要的性质之一是，它指出了当变元增大时函数ff的最大增大率。相反，梯度的负值（负梯度）指出了当变元增大时函数ff的最大减小率。根据这样一种性质，即可设计出求函数极小值的迭代算法。

类似地，实值函数$f(\boldsymbol{x})$相对于$1×n$行向量$x^T$的梯度为$1×n$行向量，定义为：
$$
\nabla_{\boldsymbol{x}^T}f(\boldsymbol{x})=\left[\frac{\partial f(\boldsymbol{x})}{\partial x_1},\frac{\partial f(\boldsymbol{x})}{\partial x_2},\ldots,\frac{\partial f(\boldsymbol{x})}{\partial x_n}\right]=\frac{\partial f(\boldsymbol{x})}{\partial\boldsymbol{x}^T}
$$
$m$维行向量函数$\boldsymbol{f}(\boldsymbol{x})=[f_1(\boldsymbol{x}),\ldots,f_m(\boldsymbol{x})]$，相对于$n$维实向量$\boldsymbol{x}$的梯度为$n×m$矩阵定义为：
$$
\begin{aligned}\frac{\partial\boldsymbol{f}(\boldsymbol{x})}{\partial\boldsymbol{x}}&=\begin{bmatrix}\frac{\partial f_1(\boldsymbol{x})}{\partial x_1}&\frac{\partial f_2(\boldsymbol{x})}{\partial x_1}&\ldots&\frac{\partial f_m(\boldsymbol{x})}{\partial x_1}\\ \frac{\partial f_1(\boldsymbol{x})}{\partial x_2}&\frac{\partial f_2(\boldsymbol{x})}{\partial x_2}&\ldots&\frac{\partial f_m(\boldsymbol{x})}{\partial x_2}\\ \vdots&\vdots&\ldots&\vdots\\ \frac{\partial f_1(\boldsymbol{x})}{\partial x_n}&\frac{\partial f_2(\boldsymbol{x})}{\partial x_n}&\ldots&\frac{\partial f_m(\boldsymbol{x})}{\partial x_n}\end{bmatrix}=\nabla_{\boldsymbol{x}}\boldsymbol{f}(\boldsymbol{x})\end{aligned}
$$
若$m×1$向量函数$\boldsymbol{f}(\boldsymbol{x})=\boldsymbol{y}=[y_1,\ldots,y_m]^T$，其中$y_1,y_2,\ldots,y_m$是向量的标量函数，一阶梯度：
$$
\frac{\partial\boldsymbol{y}}{\partial\boldsymbol{x}^T}=\begin{bmatrix}\frac{\partial y_1}{\partial x_1}&\frac{\partial y_1}{\partial x_2}&\cdots&\frac{\partial y_1}{\partial x_n}\\ \frac{\partial y_2}{\partial x_1}&\frac{\partial y_2}{\partial x_2}&\cdots&\frac{\partial y_2}{\partial x_n}\\ \vdots&\vdots&\cdots&\vdots\\ \frac{\partial y_m}{\partial x_1}&\frac{\partial y_m}{\partial x_2}&\cdots&\frac{\partial y_m}{\partial x_n}\end{bmatrix}
$$
$\frac{\partial\boldsymbol{y}}{\partial\boldsymbol{x}^T}$是一个$m×n$的矩阵，称为向量函数$\boldsymbol{y}=[y_1,y_2,\ldots,y_m]^T$的 Jacobi 矩阵。

若$\boldsymbol{f}(\boldsymbol{x}) = [x_{1},x_{2},\ldots ,x_{n}]$，则:
$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T}}{\partial \boldsymbol{x}} = \boldsymbol{I} \end{equation}
$$
这个结论非常重要，将帮助我们导出更多有用的结论。



若$\boldsymbol{A}$与$\boldsymbol{y}$均和$\boldsymbol{x}$无关，则：
$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{y}}{\partial \boldsymbol{x}} = \frac{\partial \boldsymbol{x}^{T}}{\partial \boldsymbol{x}}\boldsymbol{A}\boldsymbol{y} = \boldsymbol{A}\boldsymbol{y} \end{equation}
$$


因为$\boldsymbol{y}^{T}\boldsymbol{A}\boldsymbol{x} = \langle \boldsymbol{A}^{T}\boldsymbol{y},\boldsymbol{x} \rangle = \langle \boldsymbol{x},\boldsymbol{A}^{T}\boldsymbol{y} \rangle = \boldsymbol{x}^{T}\boldsymbol{A}^{T} \boldsymbol{y}$，则：
$$
\begin{equation}\frac{\partial \boldsymbol{y}^{T}\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}} = \boldsymbol{A}^{T}\boldsymbol{y} \end{equation}
$$
由于：
$$
\begin{equation}x^{T}\boldsymbol{A}\boldsymbol{x} = \sum_{i=1}^{n}\sum_{j=1}^{n}A_{ij}x_{i}x_{j} \end{equation}
$$
所以梯度$\frac{\partial\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}}$的第k个分量为：
$$
\begin{equation}\bigg[ \frac{\partial \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}} \bigg]_{k} = \frac{\partial}{\partial x_{k}} \sum_{i=1}^{n}\sum_{j=1}^{n}A_{ij}x_{i}x_{j} = \sum_{i=1}^{n}A_{ik}x_{i} + \sum_{j=1}^{n}A_{kj}x_{j} \end{equation}
$$
即有：
$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}} = \boldsymbol{A}\boldsymbol{x} + \boldsymbol{A}^{T}\boldsymbol{x} \end{equation}
$$
特别的如果$\boldsymbol{A}$为对称矩阵则有：
$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}} = 2\boldsymbol{A}\boldsymbol{x} \end{equation}
$$
归纳以上三个例子的结果以及其他结果，便得到实值函数$f(\boldsymbol{x})$相对于列向量$\boldsymbol{x}$的一下几个常用的梯度公式。

若$f(\boldsymbol{x}) = c$为常数，则梯度$\frac{\partial c}{\partial \boldsymbol{x}} = 0$

**线性法则**：若$f(\boldsymbol{x})$和$g(\boldsymbol{x})$分别是向量$\boldsymbol{x}$的实值函数，$c_{1}$和$c_{2}$为实常数，则：
$$
\begin{equation}\frac{\partial[c_{1}f(\boldsymbol{x}) + c_{2}g(\boldsymbol{x})]}{\partial \boldsymbol{x}} = c_{1}\frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}} + c_{2}\frac{\partial g(\boldsymbol{x})}{\partial \boldsymbol{x}} \end{equation}
$$
**乘法法则**：若$f(\boldsymbol{x})$和$g(\boldsymbol{x})$都是向量$\boldsymbol{x}$的实值函数，则：
$$
\begin{equation}\frac{f(\boldsymbol{x})g(\boldsymbol{x})}{\partial \boldsymbol{x}} = g(\boldsymbol{x})\frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}} + f(\boldsymbol{x}) \frac{\partial g(\boldsymbol{x})}{\partial \boldsymbol{x}} \end{equation}
$$
**商法则**：若$g(\boldsymbol{x})\neq 0$，则：
$$
\begin{equation}\frac{\partial f(\boldsymbol{x})/g(\boldsymbol{x})}{\partial \boldsymbol{x}} = \frac{1}{g^{2}(\boldsymbol{x})}\bigg[ g(\boldsymbol{x})\frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}} - f(\boldsymbol{x}) \frac{\partial g(\boldsymbol{x})}{\partial \boldsymbol{x}} \bigg] \end{equation}
$$
**链式法则**：若$\boldsymbol{y}(\boldsymbol{x})$是$\boldsymbol{x}$的向量值函数，则：
$$
\begin{equation}\frac{\partial f(\boldsymbol{y}(\boldsymbol{x}))}{\partial \boldsymbol{x}} = \frac{\partial \boldsymbol{y}^{T}(\boldsymbol{x})}{\partial \boldsymbol{x}}\frac{\partial f(\boldsymbol{y})}{\partial \boldsymbol{y}} \end{equation}
$$
式中$\frac{ \partial\boldsymbol{y}^{T}(\boldsymbol{x})}{\partial \boldsymbol{x}}$为$n\times n$矩阵。

#### 例子

若$n\times 1$向量$\boldsymbol{a}$与$\boldsymbol{x}$是无关的常数向量，则：

$$
\begin{equation}\frac{\partial \boldsymbol{a}^{T}\boldsymbol{x}}{\partial \boldsymbol{x}} = \boldsymbol{a} \qquad \frac{\partial\boldsymbol{x}^{T}\boldsymbol{a}}{\partial \boldsymbol{x}} = \boldsymbol{a} \end{equation}
$$
若$n\times 1$向量$\boldsymbol{a}$与$\boldsymbol{x}$是无关的常数向量，则：

$$
\begin{equation}\frac{\partial\boldsymbol{a}^{T}\boldsymbol{y}(\boldsymbol{x})}{\partial \boldsymbol{x}} = \frac{\partial \boldsymbol{y}^{T}(\boldsymbol{x})}{\partial \boldsymbol{x}} \boldsymbol{a} \qquad \frac{\partial\boldsymbol{y}^{T}(\boldsymbol{x})\boldsymbol{a}}{\partial \boldsymbol{x}} =\frac{\partial\boldsymbol{y}^{T}(\boldsymbol{x})}{\partial \boldsymbol{x}} \boldsymbol{a} \end{equation}
$$

若$\boldsymbol{A}$和$\boldsymbol{y}$均与$\boldsymbol{x}$无关，则：

$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{y}}{\partial \boldsymbol{x}} = \boldsymbol{A}\boldsymbol{y} \qquad \frac{\partial \boldsymbol{y}^{T}\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}} = \boldsymbol{A}^{T}\boldsymbol{y} \end{equation}
$$

若$\boldsymbol{A}$是与$\boldsymbol{x}$无关，而$\boldsymbol{y}(\boldsymbol{x})$与向量$\boldsymbol{x}$的元素有关，则：

$$
\begin{equation}\frac{\partial[\boldsymbol{y}(\boldsymbol{x})]^{T} \boldsymbol{A}\boldsymbol{y}(\boldsymbol{x})}{\partial \boldsymbol{x}} = \frac{\partial[\boldsymbol{y}(\boldsymbol{x})]^{T}}{\partial \boldsymbol{x}}(\boldsymbol{A} + \boldsymbol{A}^{T})\boldsymbol{y}(\boldsymbol{x}) \end{equation}
$$
若$\boldsymbol{A}$是一个与向量$\boldsymbol{x}$无关的矩阵，而$\boldsymbol{y}(\boldsymbol{x})$和$\boldsymbol{z}(\boldsymbol{x})$是与向量$\boldsymbol{x}$的元素有关的列向量，则：

$$
\begin{equation}\frac{[\boldsymbol{y}(\boldsymbol{x})]^{T} \boldsymbol{A}\boldsymbol{z}(\boldsymbol{x})}{\partial \boldsymbol{x}} = \frac{[\boldsymbol{y}(\boldsymbol{x})]^{T}}{\partial \boldsymbol{x}} \boldsymbol{A}\boldsymbol{z}(\boldsymbol{x}) + \frac{[\boldsymbol{z}(\boldsymbol{x})]^{T}}{\partial \boldsymbol{x}}\boldsymbol{A}^{T}\boldsymbol{y}(\boldsymbol{x}) \end{equation}
$$
令$\boldsymbol{x}$为$n\times 1$向量，$\boldsymbol{a}$为$m\times 1$常数向量，$\boldsymbol{A}$和$\boldsymbol{B}$分别为$m\times n$和$m\times m$常数矩阵，且$\boldsymbol{B}$为对称矩阵，则：

$$
\begin{equation}\frac{\partial (\boldsymbol{a} - \boldsymbol{A} \boldsymbol{x})^{T}\boldsymbol{B}(\boldsymbol{a} - \boldsymbol{A}\boldsymbol{x})}{\partial \boldsymbol{x}} = -2\boldsymbol{A}^{T}\boldsymbol{B}(\boldsymbol{a} - \boldsymbol{A}\boldsymbol{x}) \end{equation}
$$
### 实值函数的梯度矩阵

在最优化问题中，需要最优化的对象可能是某个加权矩阵。因此，有必要分析实值函数相对于矩阵变元的梯度。

实值函数$f(\boldsymbol{A})$相对于$m\times n$是矩阵$\boldsymbol{A}$的梯度为$m\times n$矩阵，简称梯度矩阵，定义为：

$$
\begin{equation}\frac{\partial f(\boldsymbol{A})}{\partial \boldsymbol{A}} = \begin{bmatrix} \frac{\partial f(\boldsymbol{A})}{\partial A_{11}} & \frac{\partial f(\boldsymbol{A})}{\partial A_{12}} & \ldots & \frac{\partial f(\boldsymbol{A})}{\partial A_{1n}} \\ \frac{\partial f(\boldsymbol{A})}{\partial A_{21}} & \frac{\partial f(\boldsymbol{A})}{\partial A_{22}} & \ldots & \frac{\partial f(\boldsymbol{A})}{\partial A_{2n}} \\ \vdots & \vdots & \ldots & \vdots \\ \frac{\partial f(\boldsymbol{A})}{\partial A_{m1}} & \frac{\partial f(\boldsymbol{A})}{\partial A_{m2}} & \ldots & \frac{\partial f(\boldsymbol{A})}{\partial A_{mn}} \end{bmatrix} \end{equation}
$$


式中$A_{ij}$是$\boldsymbol{A}$的元素。

实值函数相对于矩阵变元的梯度具有以下性质：

若$f(\boldsymbol{A}) = c$是常数，其中$\boldsymbol{A}$为$m\times n$矩阵，则梯度$\frac{\partial c}{\partial \boldsymbol{A}} = \boldsymbol{O}_{m\times n}$

**线性法则**：若$f(\boldsymbol{A})$和$g(\boldsymbol{A})$分别是矩阵$\boldsymbol{A}$的实值函数,$c_{1}$,$c_{2}$均为实常数，则：
$$
\begin{equation}\frac{\partial [c_{1}f(\boldsymbol{A}) + c_{2}g(\boldsymbol{A})]}{\partial \boldsymbol{A}} = c_{1}\frac{\partial f(\boldsymbol{A})}{\partial \boldsymbol{A}} + c_{2}\frac{\partial g(\boldsymbol{A})}{\partial \boldsymbol{A}} \end{equation}
$$

**乘积法则**：若$f(\boldsymbol{A})$，$g(\boldsymbol{A})$都是矩阵$\boldsymbol{A}$的实值函数，则：
$$
\begin{equation}\frac{\partial f(\boldsymbol{A})g(\boldsymbol{A})}{\partial \boldsymbol{A}} = f(\boldsymbol{A})\frac{\partial g(\boldsymbol{A})}{\partial \boldsymbol{A}} + g(\boldsymbol{A}) \frac{\partial f(\boldsymbol{A})}{\partial \boldsymbol{A}} \end{equation}
$$

**商法则**：若$g(\boldsymbol{A})\neq 0$，则：
$$
\begin{equation}\frac{\partial f(\boldsymbol{A})/g(\boldsymbol{A})}{\partial \boldsymbol{A}} = \frac{1}{[g(\boldsymbol{A})]^{2}} \bigg[ g(\boldsymbol{A}) \frac{\partial f(\boldsymbol{A})}{\partial \boldsymbol{A}} - f(\boldsymbol{A}) \frac{\partial g(\boldsymbol{A})}{\partial \boldsymbol{A}} \bigg] \end{equation}
$$



**链式法则**：令$\boldsymbol{A}$为$m\times n$的矩阵，且$y=f(\boldsymbol{A})$和$g(y)$分别是以矩阵$\boldsymbol{A}$和标量$y$为变元的实值函数，则：

$$
\begin{equation}\frac{\partial g(f(\boldsymbol{A}))}{\partial \boldsymbol{A}} = \frac{\mathrm{d}g(y)}{\mathrm{d} y}\frac{\partial f(\boldsymbol{A})}{\partial \boldsymbol{A}} \end{equation}
$$

#### 例子

若$\boldsymbol{A}\in R^{m\times n}$,$\boldsymbol{x}\in R^{m\times 1}$,$\boldsymbol{y}\in R^{n\times 1}$，则：
$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{y}}{\partial \boldsymbol{A}} = \boldsymbol{x}\boldsymbol{y}^{T} \end{equation}
$$


若$\boldsymbol{A}\in R^{n\times n}$非奇异，$\boldsymbol{x}\in R^{n\times 1}$,$\boldsymbol{y}\in R^{n\times 1}$,则：

$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T} \boldsymbol{A}^{-1}\boldsymbol{y}}{\partial \boldsymbol{A}} = -\boldsymbol{A}^{-T}\boldsymbol{x}\boldsymbol{y}^{T}\boldsymbol{A}^{-T} \end{equation}
$$


若$\boldsymbol{A}\in R^{m\times n}$,$\boldsymbol{x}\in R^{n\times 1}$,$\boldsymbol{y}\in R^{n\times 1}$，则：
$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T} \boldsymbol{A}^{T}\boldsymbol{A}\boldsymbol{y}}{\partial \boldsymbol{A}} = \boldsymbol{A}(\boldsymbol{x}\boldsymbol{y}^{T} + \boldsymbol{y}\boldsymbol{x}^{T}) \end{equation}
$$
若$\boldsymbol{A}\in R^{m\times n}$,$\boldsymbol{x}$,$\boldsymbol{y}\in R^{m\times 1}$，则：

$$
\begin{equation}\frac{\partial \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{A}^{T}\boldsymbol{y}}{\partial \boldsymbol{A}} = (\boldsymbol{x}\boldsymbol{y}^{T} + \boldsymbol{y}\boldsymbol{x}^{T})\boldsymbol{A} \end{equation}
$$
指数函数的梯度：
$$
\begin{equation}\frac{\partial \exp(\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{y})}{\partial \boldsymbol{A}} = \boldsymbol{x}\boldsymbol{y}^{T} \exp(\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{y}) \end{equation}
$$

### 迹函数的梯度矩阵

有时候，二次型目标函数可以利用矩阵的迹加以重写。因为一标量可以视为$1\times 1$的矩阵，所以二次型目标函数的迹直接等同于函数本身，即$f(\boldsymbol{x}) = \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x} = \mathrm{tr}(\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}) $ 利用迹的性质，又可以将目标函数进一步表示为：

$$
\begin{equation}f(\boldsymbol{x}) = \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x} = \mathrm{tr}(\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}) = \mathrm{tr}(\boldsymbol{A}\boldsymbol{x}\boldsymbol{x}^{T}) \end{equation}
$$
因此，二次型目标函数$\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}$等于核矩阵$\boldsymbol{A}$和向量外积$\boldsymbol{x}\boldsymbol{x}^{T}$的乘积的迹
$$
\mathrm{tr}(\boldsymbol{A}\boldsymbol{x}\boldsymbol{x}^{T})
$$


对于$n\times n$矩阵$\boldsymbol{A}$,由于$\mathrm{tr}(\boldsymbol{A}) = \sum_{i=1}^{n}A_{ii}$，故梯度$\frac{\partial \mathrm{tr}(\boldsymbol{A})}{\partial \boldsymbol{A}}$的$(i,j)$元素为：
$$
\begin{equation}\bigg[\frac{\partial \mathrm{tr}(\boldsymbol{A})}{\partial \boldsymbol{A}} \bigg]_{ij} = \frac{\partial}{\partial A_{ij}}\sum_{k=1}^{n}A_{kk} = \begin{cases} 1 & j=i \\ 0 & j\neq i \end{cases} \end{equation}
$$
所以有$\frac{\partial \mathrm{tr}(\boldsymbol{A})}{\partial \boldsymbol{A}} = \boldsymbol{I}$



考察目标函数$f(\boldsymbol{A}) = \mathrm{tr}(\boldsymbol{A}\boldsymbol{B})$，其中$\boldsymbol{A}$和$\boldsymbol{B}$分别为$m\times n$和$mn\times m$实矩阵。首先，矩阵乘积的元素为$[\boldsymbol{A}\boldsymbol{B}]_{ij} = \sum_{l=1}^{n}A_{il}B_{lj}$，故矩阵乘积的迹$\mathrm{tr}(\boldsymbol{A}\boldsymbol{B}) = \sum_{p=1}^{m}\sum_{l=1}^{n}A_{pl}B_{lp}$，于是，梯度$\frac{\partial \mathrm{tr}(\boldsymbol{A}\boldsymbol{B})}{\partial \boldsymbol{A}}$是一个$m\times n$矩阵，其元素为：

$$
\begin{equation}\bigg[ \frac{\partial \mathrm{tr}(\boldsymbol{A}\boldsymbol{B})}{\partial \boldsymbol{A}} \bigg]_{ij} = \frac{\partial }{\partial A_{ij}} \bigg(\sum_{p=1}^{m}\sum_{l=1}^{n}A_{pl}B_{lp} \bigg) = B_{ji} \end{equation}
$$
所以有:
$$
\begin{equation}\frac{\partial \mathrm{tr}(\boldsymbol{A}\mathrm{B})}{\partial \boldsymbol{A}} = \nabla_{\boldsymbol{A}} \mathrm{tr}(\boldsymbol{A}\mathrm{B}) = \boldsymbol{B}^{T} \end{equation}
$$
由于$\mathrm{tr}(\boldsymbol{B}\boldsymbol{A}) = \mathrm{tr}(\boldsymbol{A}\boldsymbol{B})$所以：

$$
\begin{equation}\frac{ \partial \mathrm{tr}(\boldsymbol{A}\mathrm{B}) }{\partial \boldsymbol{A}} = \frac{\partial \mathrm{tr}(\boldsymbol{B}\boldsymbol{A})}{\partial \boldsymbol{A}} = \boldsymbol{B}^{T} \end{equation}
$$
同理，由于$\mathrm{tr}(\boldsymbol{x}\boldsymbol{y}^{T}) = \mathrm{tr}(\boldsymbol{y}\boldsymbol{x}^{T}) = \boldsymbol{x}^{T}\boldsymbol{y}$，所以有：
$$
\begin{equation}\frac{\partial \mathrm{tr}(\boldsymbol{x}\boldsymbol{y}^{T})}{\partial \boldsymbol{x}} = \frac{\partial \mathrm{tr}(\boldsymbol{y}\boldsymbol{x}^{T})}{\partial \boldsymbol{x}} = \boldsymbol{y} \end{equation}
$$
### Hessian 矩阵

实值函数$f(\boldsymbol{x})$相对于$m\times 1$实向量$\boldsymbol{x}$的二阶偏导是一个由$m^{2}$个二阶偏导组成的矩阵，称为 Hessian 矩阵，定义为：
$$
\begin{equation}\frac{\partial^{2} f(\boldsymbol{x})}{\partial \boldsymbol{x} \partial \boldsymbol{x}^{T}} = \frac{\partial}{\partial \boldsymbol{x}^{T}} \bigg[\frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}} \bigg] \end{equation}
$$
或者简写为梯度的梯度：

$$
\begin{equation}\nabla_{\boldsymbol{x}}^{2}f(\boldsymbol{x}) = \nabla_{\boldsymbol{x}} (\nabla_{\boldsymbol{x}} f(\boldsymbol{x})) \end{equation}
$$
根据定义,Hessian 矩阵的第j列是梯度$\frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}} = \nabla_{\boldsymbol{x}} f(\boldsymbol{x})$第$j$个分量的梯度，即：
$$
\begin{equation}\bigg[ \frac{\partial^{2}f(\boldsymbol{x}) }{\partial \boldsymbol{x} \partial \boldsymbol{x}^{T}} \bigg]_{i,j} = \frac{\partial^{2}f(\boldsymbol{x})}{\partial x_{i} \partial x_{j}} \end{equation}
$$
或者可以写作：

$$
\begin{equation}\frac{\partial^{2} f(\boldsymbol{x})}{\partial \boldsymbol{x} \partial \boldsymbol{x}^{T}} = \begin{bmatrix} \frac{\partial^{2}f}{\partial x_{1}\partial x_{1}} & \frac{\partial^{2}f}{\partial x_{1}\partial x_{2}} & \ldots & \frac{\partial^{2}f}{\partial x_{1}\partial x_{n}} \\ \frac{\partial^{2}f}{\partial x_{2}\partial x_{1}} & \frac{\partial^{2}f}{\partial x_{2}\partial x_{2}} & \ldots & \frac{\partial^{2}f}{\partial x_{2}\partial x_{n}} \\ \vdots & \vdots & \ddots & \vdots \\ \frac{\partial^{2}f}{\partial x_{n}\partial x_{1}} & \frac{\partial^{2}f}{\partial x_{n}\partial x_{2}} & \ldots & \frac{\partial^{2}f}{\partial x_{n}\partial x_{n}} \\ \end{bmatrix} \end{equation}
$$
因此，Hessian 矩阵可以通过两个步骤计算得出：

1. 求实值函数$f(\boldsymbol{x})$关于向量变元$\boldsymbol{x}$的偏导数，得到实值函数的梯度$\frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}}$
2. 再求梯度$\frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}}$相对于$1\times n$行向量$\boldsymbol{x}^{T}$的偏导数，得到梯度的梯度即 Hessian 矩阵

根据以上步骤，得到 Hessian 矩阵的下列公式。

对于$n\times 1$的常数向量$\boldsymbol{a}^{T}$，有：
$$
\begin{equation}\frac{\partial^{2} \boldsymbol{a}^{T}\boldsymbol{x}}{\partial \boldsymbol{x}\partial \boldsymbol{x}^{T}} = \boldsymbol{O}_{n\times n} \end{equation}
$$
若$\boldsymbol{A}$是$n\times n$矩阵，则：

$$
\begin{equation}\frac{\partial^{2} \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}\partial \boldsymbol{x}^{T}} = \boldsymbol{A} + \boldsymbol{A}^{T} \end{equation}
$$
令$\boldsymbol{x}$为$n\times 1$向量，$\boldsymbol{a}$为$m\times 1$常数向量，$\boldsymbol{A}$和$\boldsymbol{B}$分别为$m\times n$和$m\times m$常数矩阵，且$\boldsymbol{B}$为对称矩阵，则：
$$
\begin{equation}\frac{\partial^{2}(\boldsymbol{a} - \boldsymbol{A}\boldsymbol{x})^{T}\boldsymbol{B} (\boldsymbol{a} - \boldsymbol{A}\boldsymbol{x}) }{\partial \boldsymbol{x} \partial \boldsymbol{x}^{T}} = 2\boldsymbol{A}^{T}\boldsymbol{B}\boldsymbol{A} \end{equation}
$$




### 利用全微分求导

**矩阵的迹** tr(A)与一阶实矩阵微分dX
$$
\begin{equation}
A = \left[ {\left. {\begin{array}{*{20}{c}}
  {{a_{11}}}&{{a_{12}}}&{...}&{{a_{1n}}} \\ 
  {{a_{21}}}&{{a_{22}}}&{...}&{{a_{2n}}} \\ 
  {...}&{...}&{...}&{...} \\ 
  {{a_{n1}}}&{{a_{n2}}}&{...}&{{a_{nn}}} 
\end{array}} \right]} \right.
\end{equation}
$$

矩阵的迹：$tr(A) = {a_{11}} + {a_{22}} +  \cdot  \cdot  \cdot  + {a_{n}} = \sum\limits_{i = 1}^n {{a_{ii}}}$

只有**方阵**才有迹

交换律：$tr(AB) = tr(BA),{A_{m \times n}},{B_{n \times m}}$

**矩阵变元**的**实值标量函数**的**全微分**：$df(X) = tr(\frac{{\partial f(X)}}{{\partial {X^T}}}dX)$

矩阵变元或向量变元的实值标量函数的**矩阵求导**的结果，都可以通过上式求解

使用**矩阵微分**求导：

对于实值标量函数$f(X),tr(f(X))=f(X),df(X)=tr(df(X))$,所以有$df(X)=tr(df(X))=d(trf(X))$

如果实值标量函数本身就是某个**矩阵函数**${F_{p \times p}}(X)$的迹，如$reF(X)$，则由全微分的线性法则得：
$$
\begin{equation}d(tr{F_{p \times p}}(X)) = d(\sum\limits_{i = 1}^p {{f_{ii}}(X)} ) = \sum\limits_{i = 1}^p {d({f_{ii}}(X)) = tr(d{F_{p \times p}}(X))}\end{equation}
$$

### 常见的求导

- $\frac{{\partial ({x^T}a)}}{{\partial x}} = \frac{{\partial ({a^T}x)}}{{\partial x}} = a$
- $\frac{{\partial ({x^T}x)}}{{\partial x}} = 2x$
- $\frac{{\partial ({x^T}Ax)}}{{\partial x}} = Ax + {A^T}x,{A_{n \times n}} = ({a_{ij}})_{i = 1,j = 1}^{n,n}$
- $\frac{{\partial ({a^T}x{x^T}b)}}{{\partial x}} = a{b^T}x + b{a^T}x,a = {({a_1},{a_2},...,{a_n})^T},b = {({b_1},{b_2},...,{b_n})^T}$
- $\frac{{\partial ({a^T}xb)}}{{\partial x}} = a{b^T},{a_{m \times 1}},{b_{n \times 1}},{x_{m \times n}}$
- $\frac{{\partial ({a^T}{x^T}b)}}{{\partial x}} = b{a^T},{a_{m \times 1}},{b_{n \times 1}},{x_{m \times n}}$
- $\frac{{\partial ({a^T}x{x^T}b)}}{{\partial x}} = a{b^T}x + b{a^T}x,{a_{m \times 1}},{b_{m \times 1}},{x_{m \times m}}$
- $\frac{{\partial ({a^T}{x^T}xb)}}{{\partial x}} = xa{b^T} + xb{a^T},{a_{m \times 1}},{b_{m \times 1}},{x_{m \times m}}$

#### 常用的结论：

证明：$d\left| X \right| = \left| X \right|tr({X^{ - 1}}dX)$
$$
\left| X \right| = {x_{i1}}{A_{i1}} + {x_{i2}}{A_{i2}} + ... + {x_{in}}{A_{in}}
$$

$$
\frac{{\partial \left| X \right|}}{{\partial {x_{ij}}}} = {A_{ij}}
$$

$$
\frac{{\partial \left| X \right|}}{{\partial {X^T}}} =\begin{bmatrix}
  {{A_{11}}}&{{A_{21}}}& \cdots &{{A_{n1}}} \\ 
  {{A_{12}}}&{{A_{22}}}& \cdots &{{A_{n2}}} \\ 
  \cdots&\cdots&\ddots&\cdots \\ 
  {{A_{1n}}}&{{A_{2n}}}&\cdots&{{A_{nn}}} 

\end{bmatrix}= {X^*} = \left| X \right|{X^{ - 1}}
$$
$$
d\left| X \right| = tr(\frac{{\partial \left| X \right|}}{{\partial {X^T}}}dX) = tr(\left| X \right|{X^{ - 1}}dX)
$$

$d({X^{ - 1}}) =  - {X^{ - 1}}dX({X^{ - 1}})$

令A为在**不考虑**矩阵变元X是对称矩阵的前提下，得到的 Jacobian 矩阵
$$
\begin{equation}
A = \begin{bmatrix}
{{{\partial f} \over {\partial {x_{11}}}}} & {{{\partial f} \over {\partial {x_{21}}}}} & {...} & {{{\partial f} \over {\partial {x_{n1}}}}}  \\ 
   {{{\partial f} \over {\partial {x_{12}}}}} & {{{\partial f} \over {\partial {x_{22}}}}} & {...} & {{{\partial f} \over {\partial {x_{n2}}}}}  \\ 
   {...} & {...} & {...} & {...}  \\ 
   {{{\partial f} \over {\partial {x_{1n}}}}} & {{{\partial f} \over {\partial {x_{2n}}}}} & {...} & {{{\partial f} \over {\partial {x_{n}}}}}
\end{bmatrix}_{n \times n}
 \end{equation}
$$
**对称矩阵变元的实值标量函数**的求导公式
$$
\frac{{\partial f(X)}}{{\partial {X_{n \times n}}}} = \frac{{\partial f(X)}}{{\partial X_{n \times n}^T}} = {A^T} + A - (A \circ E)
$$
设$x \sim {N_p}(\mu ,\sum ),\sum  > 0$，$\sum$为**正定**的协方差矩阵，则$x$的概率密度函数为
$$
f(\boldsymbol{x}) = \frac{1}{{{{(2\pi )}^{\frac{p}{2}}}{{\left| \sum  \right|}^{\frac{1}{2}}}}}{e^{ - \frac{1}{2}{{(\boldsymbol{x} - \mu )}^T}{\sum ^{ - 1}}(\boldsymbol{x} - \mu )}}
$$
对数似然函数：
$$
\ln L(\mu ,\sum ) = \ln (\prod\limits_{i = 1}^n {f({x_i})}) =  - \frac{p}{2}n\ln (2\pi ) - \frac{1}{2}n\ln \left| \sum  \right| - \frac{1}{2}\sum\limits_{i = 1}^n {[{{({x_i} - \mu )}^T}{\sum ^{ - 1}}({x_i} - \mu )]}
$$
求导：$\frac{{\partial (\ln L(\mu ,\sum ))}}{{\partial \mu }} = {\sum ^{ - 1}}\sum\limits_{i = 1}^n {({x_i} - \mu )}$
$$
\frac{{\partial (\ln L(\mu ,\sum ))}}{{\partial \sum }} = {\sum ^{ - 1}}(\sum\limits_{i = 1}^n {[({x_i} - \mu ){{({x_i} - \mu )}^T}]} ){\sum ^{ - 1}} - n{\sum ^{ - 1}} \\
- \{ [\frac{1}{2}({\sum ^{ - 1}}(\sum\limits_{i = 1}^n {[({x_i} - \mu ){{({x_i} - \mu )}^T}]} ){\sum ^{ - 1}} - n{\sum ^{ - 1}}] \circ E\}
$$
令导数为零，得：
$$
\begin{gathered}
  \mu  = \overline x  = \frac{1}{n}\sum\limits_{i = 1}^n {{x_i}}   \\
  \sum  = \frac{1}{n}\sum\limits_{i = 1}^n {[({x_i} - } \overline x ){({x_i} - \overline x )^T}]  \\ 
\end{gathered}
$$



## Hermitian 矩阵的特征值和特征向量

在信号处理领域，经常碰到对称矩阵。复对称矩阵又称为Hermitian矩阵。比如对于实观测数据$x(t)$，其自相关矩阵$R=E[x(t)x^T(t)]$是实对称矩阵，而复观测信号的自相关矩阵是Hermitian矩阵。Hermitian在计算过程中有一系列重要特性，可以大大简化计算过程。本文总结Hermitian矩阵特征值和特征向量的一些性质。

### 重要性质

1. 特征值的实数性
   Hermitian 矩阵$A$的特征值一定是实的。

   证明：令λ和$\boldsymbol{u}$分别是Hermitian矩阵A的特征值和与之对应的特征向量，即$A\boldsymbol{u}=λ\boldsymbol{u}$。两边同时左乘特征向量的共轭转置，得二次型标量值函数$\boldsymbol{u}^TA\boldsymbol{u}=λ\boldsymbol{u}^T\boldsymbol{u}$，对其两边取共轭转置，得到$\boldsymbol{u}^TA\boldsymbol{u}=λ^T\boldsymbol{u}^T u$。注意内积$\boldsymbol{u}^T\boldsymbol{u}$总是实数，则有$λ$也一定是实数。

2. 可逆矩阵的特征对关系
   令$λ,\boldsymbol{u}$是Hermitian矩阵$A$的特征对。若$A$可逆，则$1/λ,\boldsymbol{u}$是逆矩阵$A^{-1}$的特征对。
   证明：因为$A\boldsymbol{u}=λ\boldsymbol{u}$，则对两边左乘$A^{-1}$，则有$\boldsymbol{u}=λA^{-1}\boldsymbol{u}$，所以有$λ^{-1}\boldsymbol{u}=A^{-1}\boldsymbol{u}$

### 特征向量求解步骤

对于$n\times n$的Hermitian矩阵$A$，若它所有不同的特征值$λ_1,λ_2,…,λ_n$都通过求解特征方程获得。那么求解其特征向量可以通过以下两个步骤完成：

1. 利用高斯消元法求解方程：
   $$
   (A-λI)x=0
   $$
   得到与每个已知λ对应的非零解$x$

2. 利用Gram-Schmidt正交化方法将$x$正交化，得到相互正交，并且具有单位范数的特征向量。

若$λ_k$是Hermitian矩阵$A$的多重特征值，并且其多重度为 $m_k$，那么 $\boldsymbol{rank}(A−λ_kI)=n−m_k$，因此任何一个Hermitian矩阵都满足可对角化定理的充要条件。因此，有$U^{−1}AU=Σ$。

### 重要定理

Hermitian矩阵的所有特征向量线性无关，并且相互正交。特征矩阵$\boldsymbol{U}=[\boldsymbol{u}_1,…,\boldsymbol{u}_n]$是酉矩阵，满足$\boldsymbol{U}^{-1}=U^T$

证明过程：

1. 首先证明不同特征值对应的特征向量是相互正交的
   令$λ_1≠λ_2$是Hermitian矩阵A对应的特征值，且其对应的特征向量分别是$\boldsymbol{u}_1,\boldsymbol{u}_2$，则有：
   $$
   \boldsymbol{u}_2^T\boldsymbol{A}\boldsymbol{u}_1=\lambda_1\boldsymbol{u}_2^T\boldsymbol{u}_1
   $$

   $$
   \boldsymbol{u}_1^T\boldsymbol{A}\boldsymbol{u}_2=\lambda_2\boldsymbol{u}_1^T\boldsymbol{u}_2
   $$

2. 对前一个式子取共轭，则有：
   $$
   \boldsymbol{u}_1^T\boldsymbol{A}\boldsymbol{u}_2=\lambda_1\boldsymbol{u}_1^T\boldsymbol{u}_2
   $$
   因此有：$\lambda_1\boldsymbol{u}_1^T\boldsymbol{u}_2=\lambda_2\boldsymbol{u}_1^T\boldsymbol{u}_2$，由于$λ_1≠λ_2$，所以  $\boldsymbol{u}_1$和 $\boldsymbol{u}_2$ 正交。

更进一步

对于若$n×n$矩阵A，若$λ_k$是Hermitian矩阵$A$的多重特征值，并且其多重度为 $m_k$，那么 $\boldsymbol{rank}(A−λ_kI)=n−m_k$，并 且$A−λ_kI$是可逆的。于是，方程$(A−λ_kI)u=0$的线性无关解。这些线性无关解是正交的。由于特征矩阵U的所有特征向量即线性无关，又相互正交，故U为酉矩阵，满足$UU^T=I$，即$U^T=U^{−1}$

### 矩阵表示形式

对于Hermitian矩阵有：

1. 正交相似形式：
   $$
   \boldsymbol{U}^T\boldsymbol{A}\boldsymbol{U}=\boldsymbol{diag}(\lambda_1,\lambda_2,…,\lambda_n)
   $$

2. 矩阵分解形式（正交相似下的范式）：
   $$
   \boldsymbol{A}=\boldsymbol{U}Σ\boldsymbol{U}^T
   $$

3. 求和形式：
   $$
   \boldsymbol{A} = \sum_{i=1}^{n}\boldsymbol{\lambda}_i\boldsymbol{u}_i\boldsymbol{u}_i^T
   $$

#### 二次型表示

在最优化理论和信号处理中，二次型函数可表示为：

$$
\boldsymbol{X}^T\boldsymbol{A}\boldsymbol{x}=\sum_{i=1}^n\lambda_i\left|{\boldsymbol{x}^T\boldsymbol{u}_i}\right|^2
$$

#### 逆矩阵表示

$\boldsymbol{A}^{-1}$的级数展开形式：
$$
\boldsymbol{A}^{-1}=\sum_{i=1}^n\boldsymbol{\lambda}_i^{-1}\boldsymbol{u}_i\boldsymbol{u}_i^T
$$
因此若已知$\boldsymbol{A}$的特征值分解，可以很容易求出$\boldsymbol{A}^{-1}$

## 定矩阵

给定一个Hermitian矩阵（即等于其共轭转置的复矩阵） $\boldsymbol{M}$ ，对于任意非零复列向量 $z$，都有$z^H\boldsymbol{M}z$都为正，则 $\boldsymbol{M}$  是正定的。负定矩阵和负半定矩阵的定义类似，非正半定且非负半定的矩阵有时称为*不定*矩阵。

### 定义

对于对称实矩阵M：
$$
M\text{ positive-definite }\quad\Longleftrightarrow\quad\boldsymbol{x}^\top M\mathrm{~}\boldsymbol{x}>0\text{ for all }\boldsymbol{x}\in\mathbb{R}^n\setminus\{\boldsymbol{0}\}
$$

$$
M\text{ positive semi-definite}\quad\Longleftrightarrow\quad\boldsymbol{x}^\top M\mathrm{~}\boldsymbol{x}\geq0\text{ for all }\boldsymbol{x}\in\mathbb{R}^n
$$

$$
M\text{ negative-definite }\quad\Longleftrightarrow\quad\boldsymbol{x}^\top M\mathrm{~}\boldsymbol{x}<0\text{ for all }\boldsymbol{x}\in\mathbb{R}^n\setminus\{\boldsymbol{0}\}
$$

$$
M\text{ negative semi-definite }\quad\Longleftrightarrow\quad\boldsymbol{x}^\top M\mathrm{~}\boldsymbol{x}\leq0\text{ for all }\boldsymbol{x}\in\mathbb{R}^n
$$

同理对Hermitian矩阵M：
$$
M\text{ positive-definite}\quad\Longleftrightarrow\quad\boldsymbol{z}^*M\textbf{ z}>0\text{ for all }\boldsymbol{z}\in\mathbb{C}^n\setminus\{\boldsymbol{0}\}
$$
等等...

### 性质

矩阵*M*是正定的当且仅当它满足以下任一等效条件。

- M  与具有正实数项的对[角矩阵](https://en.wikipedia.org/wiki/Diagonal_matrix)[一致](https://en.wikipedia.org/wiki/Congruent_matrices)。
- M  是对称的或 Hermitian 的，并且它的所有[特征值](https://en.wikipedia.org/wiki/Eigenvalue)都是实数且正的。
- M  是对称的或 Hermitian 的，并且它的所有先导[主次要函数](https://en.wikipedia.org/wiki/Principal_minor)都是正的。
- 存在[可逆矩阵](https://en.wikipedia.org/wiki/Invertible_matrix) B   $M=B^HB$

如果矩阵满足类似的等效条件，其中“正”被“非负”替换，“可逆矩阵”被“矩阵”替换，并且单词“前导”被删除，则该矩阵是半正定矩阵。

正定和正半定实数矩阵是[凸优化](https://en.wikipedia.org/wiki/Convex_optimization)的基础，因为，给定一个二次[可微的](https://en.wikipedia.org/wiki/Differentiable_function)[多个实数变量的函数](https://en.wikipedia.org/wiki/Function_of_several_real_variables)，那么如果其[Hessian 矩阵](https://en.wikipedia.org/wiki/Hessian_matrix)（其二阶偏导数矩阵）在点p 处是正定的 , 那么函数在p附近是[凸](https://en.wikipedia.org/wiki/Convex_function)函数，反之，如果函数在 p 附近是凸函数 p , 那么 Hessian 矩阵在点p处是正半定的.



