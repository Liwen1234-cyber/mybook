## 矩阵的乘积

### 矩阵的理解

矩阵是线性空间中的线性变换的一个描述。在一个线性空间中，只要我们选定一组基，那么对于任何一个线性变换，都能够用一个确定的矩阵来加以描述

左乘矩阵是进行行操作，右乘矩阵是进行列操作。

$\mathbf{C} = \mathbf{A}\times\mathbf{B}$中的$\mathbf{B}$的列向量可以看作是以$\mathbf{A}$的列向量为基的子空间坐标。

### Hadamard哈达玛积(矩阵点乘)(Hadamard Product)

哈达玛积就是两个矩阵**对应位置的元素**相乘，布局不变。俗称**矩阵点乘**，符号是空心圆 ∘，两个矩阵的形状必须一样。

令A为在**不考虑**矩阵变元X是对称矩阵的前提下，得到的 Jacobian 矩阵
$$
A = {\left[ {\left. {\matrix{
   {{{\partial f} \over {\partial {x_{11}}}}} & {{{\partial f} \over {\partial {x_{21}}}}} & {...} & {{{\partial f} \over {\partial {x_{n1}}}}}  \cr 
   {{{\partial f} \over {\partial {x_{12}}}}} & {{{\partial f} \over {\partial {x_{22}}}}} & {...} & {{{\partial f} \over {\partial {x_{n2}}}}}  \cr 
   {...} & {...} & {...} & {...}  \cr 
   {{{\partial f} \over {\partial {x_{1n}}}}} & {{{\partial f} \over {\partial {x_{2n}}}}} & {...} & {{{\partial f} \over {\partial {x_{n}}}}}  \cr 

 } } \right]} \right._{n \times n}}
$$
**对称矩阵变元的实值标量函数**的求导公式
$\frac{{\partial f(X)}}{{\partial {X_{n \times n}}}} = \frac{{\partial f(X)}}{{\partial X_{n \times n}^T}} = {A^T} + A - (A \circ E)$

设$x \sim {N_p}(\mu ,\sum ),\sum  > 0$，$\sum$为**正定**的协方差矩阵，则x的概率密度函数为
$$
f(\mathbf{x}) = \frac{1}{{{{(2\pi )}^{\frac{p}{2}}}{{\left| \sum  \right|}^{\frac{1}{2}}}}}{e^{ - \frac{1}{2}{{(\mathbf{x} - \mu )}^T}{\sum ^{ - 1}}(\mathbf{x} - \mu )}}
$$
对数似然函数：$\ln L(\mu ,\sum ) = \ln (\prod\limits_{i = 1}^n {f({x_i})}) =  - \frac{p}{2}n\ln (2\pi ) - \frac{1}{2}n\ln \left| \sum  \right| - \frac{1}{2}\sum\limits_{i = 1}^n {[{{({x_i} - \mu )}^T}{\sum ^{ - 1}}({x_i} - \mu )]}$
求导：$\frac{{\partial (\ln L(\mu ,\sum ))}}{{\partial \mu }} = {\sum ^{ - 1}}\sum\limits_{i = 1}^n {({x_i} - \mu )}$
$$
\frac{{\partial (\ln L(\mu ,\sum ))}}{{\partial \sum }} = {\sum ^{ - 1}}(\sum\limits_{i = 1}^n {[({x_i} - \mu ){{({x_i} - \mu )}^T}]} ){\sum ^{ - 1}} - n{\sum ^{ - 1}} - \{ [\frac{1}{2}({\sum ^{ - 1}}(\sum\limits_{i = 1}^n {[({x_i} - \mu ){{({x_i} - \mu )}^T}]} ){\sum ^{ - 1}} - n{\sum ^{ - 1}}] \circ E\}
$$
令导数为零，得：
$$
\begin{gathered}
  \mu  = \overline x  = \frac{1}{n}\sum\limits_{i = 1}^n {{x_i}}  \hfill \\
  \sum  = \frac{1}{n}\sum\limits_{i = 1}^n {[({x_i} - } \overline x ){({x_i} - \overline x )^T}] \hfill \\ 
\end{gathered} 
$$

### 矩阵内积 (Iner Product of Matrices)

符号：⟨ . , . ⟩
目的：度量长度。
定义：列向量$\mathbf{a}$与行向量$\mathbf{b}$的内积是指：组成$\mathbf{a}的第$一个元素与组成$\mathbf{b}$的第一个元素的乘积，依次，m个这样的乘积的加和。例如，
$$
<\mathbf{a}，\mathbf{b}>=a_{1}b_{1}+a_{2}b_{2}​
$$

矩阵$\mathbf{A}$与矩阵$\mathbf{B}$的内积是指：组成$\mathbf{A}$的第一个向量与组成$\mathbf{B}$的第一个向量的内积，依次，m个这样的内积的加和。
$$
<\mathbf{A}，\mathbf{B}>=\sum^n_{i=1}\sum^n_{j=1}a_{ij}*b_{ij}
$$

### 克罗内克积（Kronecker Product ）

符号：⊗
LaTex: $\otimes$
定义：克罗内克积是两个任意大小的矩阵间的运算，它是张量积的特殊形式。给定$\boldsymbol{A}$和$\boldsymbol{B}$，则$\boldsymbol{A}$和$\boldsymbol{B}$的克罗内克积是一个在空间$\mathbb{R}^{\mathrm{mp}\times\mathrm{nq}}$的分块矩阵：
$$
\left.A\otimes B=\left[\begin{array}{ccc}\mathrm{a}_{11}B&\cdots&\mathrm{a}_{1\mathrm{n}}B\\\vdots&\ddots&\vdots\\\mathrm{a}_{\mathrm{m}1}B&\cdots&\mathrm{a}_{\mathrm{mn}}B\end{array}\right.\right]
$$

## 矩阵求导

### 实值函数相对于实向量的梯度

相对于$n×1$向量$x$的梯度算子记作$∇x$,定义为：
$$
\nabla_{\mathbf{x}}=\left[\frac\partial{\partial x_1},\frac\partial{\partial x_2},\ldots,\frac\partial{\partial x_n}\right]^T=\frac\partial{\partial\mathbf{x}}
$$
因此,$n×1$实向量$x$为变元的实标量函数$f(\mathbf{x})$相对于x的梯度为$n×1$的列向量，定义为：
$$
\nabla_\mathbf{x}f(\mathbf{x})=\left[\frac{\partial f(\mathbf{x})}{\partial x_1},\frac{\partial f(\mathbf{x})}{\partial x_2},\ldots,\frac{\partial f(\mathbf{x})}{\partial x_n}\right]^T=\frac{\partial f(\mathbf{x})}{\partial\mathbf{x}}
$$
梯度方向的负方向成为变元$\mathbf{x}$的梯度流(gradient flow)，记为：
$$
\dot{\mathbf{x}}=-\nabla_{{\mathbf{x}}}f(\mathbf{x})
$$
从梯度的定义式可以看出：

1. 一个以向量为变元的变量函数的梯度为一向量。
2. 梯度的每个分量给出了变量函数在该分量方向上的变化率

梯度向量最重要的性质之一是，它指出了当变元增大时函数ff的最大增大率。相反，梯度的负值（负梯度）指出了当变元增大时函数ff的最大减小率。根据这样一种性质，即可设计出求函数极小值的迭代算法。

类似地，实值函数$f(\mathbf{x})$相对于$1×n$行向量$x^T$的梯度为$1×n$行向量，定义为：
$$
\nabla_{\mathbf{x}^T}f(\mathbf{x})=\left[\frac{\partial f(\mathbf{x})}{\partial x_1},\frac{\partial f(\mathbf{x})}{\partial x_2},\ldots,\frac{\partial f(\mathbf{x})}{\partial x_n}\right]=\frac{\partial f(\mathbf{x})}{\partial\mathbf{x}^T}
$$
$m$维行向量函数$\mathbf{f}(\mathbf{x})=[f_1(\mathbf{x}),\ldots,f_m(\mathbf{x})]$，相对于$n$维实向量$\mathbf{x}$的梯度为$n×m$矩阵定义为：
$$
\begin{aligned}\frac{\partial\mathbf{f}(\mathbf{x})}{\partial\mathbf{x}}&=\begin{bmatrix}\frac{\partial f_1(\mathbf{x})}{\partial x_1}&\frac{\partial f_2(\mathbf{x})}{\partial x_1}&\ldots&\frac{\partial f_m(\mathbf{x})}{\partial x_1}\\\frac{\partial f_1(\mathbf{x})}{\partial x_2}&\frac{\partial f_2(\mathbf{x})}{\partial x_2}&\ldots&\frac{\partial f_m(\mathbf{x})}{\partial x_2}\\\vdots&\vdots&\ldots&\vdots\\\frac{\partial f_1(\mathbf{x})}{\partial x_n}&\frac{\partial f_2(\mathbf{x})}{\partial x_n}&\ldots&\frac{\partial f_m(\mathbf{x})}{\partial x_n}\end{bmatrix}=\nabla_{\mathbf{x}}\mathbf{f}(\mathbf{x})\end{aligned}
$$
若$m×1$向量函数$\mathbf{f}(\mathbf{x})=\mathbf{y}=[y_1,\ldots,y_m]^T$，其中$y_1,y_2,\ldots,y_m$是向量的标量函数，一阶梯度：
$$
\frac{\partial\mathbf{y}}{\partial\mathbf{x}^T}=\begin{bmatrix}\frac{\partial y_1}{\partial x_1}&\frac{\partial y_1}{\partial x_2}&\cdots&\frac{\partial y_1}{\partial x_n}\\\frac{\partial y_2}{\partial x_1}&\frac{\partial y_2}{\partial x_2}&\cdots&\frac{\partial y_2}{\partial x_n}\\\vdots&\vdots&\cdots&\vdots\\\frac{\partial y_m}{\partial x_1}&\frac{\partial y_m}{\partial x_2}&\cdots&\frac{\partial y_m}{\partial x_n}\end{bmatrix}
$$
$\frac{\partial\mathbf{y}}{\partial\mathbf{x}^T}$是一个$m×n$的矩阵，称为向量函数$\mathbf{y}=[y_1,y_2,\ldots,y_m]^T$的 Jacobi 矩阵。

若$\mathbf{f}(\mathbf{x}) = [x_{1},x_{2},\ldots ,x_{n}]$，则:
$$
\begin{equation}\frac{\partial \mathbf{x}^{T}}{\partial \mathbf{x}} = \mathbf{I} \end{equation}
$$
这个结论非常重要，将帮助我们导出更多有用的结论。



若$\mathbf{A}$与$\mathbf{y}$均和$\mathbf{x}$无关，则：
$$
\begin{equation}\frac{\partial \mathbf{x}^{T}\mathbf{A}\mathbf{y}}{\partial \mathbf{x}} = \frac{\partial \mathbf{x}^{T}}{\partial \mathbf{x}}\mathbf{A}\mathbf{y} = \mathbf{A}\mathbf{y} \end{equation}
$$


因为$\mathbf{y}^{T}\mathbf{A}\mathbf{x} = \langle \mathbf{A}^{T}\mathbf{y},\mathbf{x} \rangle = \langle \mathbf{x},\mathbf{A}^{T}\mathbf{y} \rangle = \mathbf{x}^{T}\mathbf{A}^{T} \mathbf{y}$，则：
$$
\begin{equation}\frac{\partial \mathbf{y}^{T}\mathbf{A}\mathbf{x}}{\partial \mathbf{x}} = \mathbf{A}^{T}\mathbf{y} \end{equation}
$$
由于：
$$
\begin{equation}x^{T}\mathbf{A}\mathbf{x} = \sum_{i=1}^{n}\sum_{j=1}^{n}A_{ij}x_{i}x_{j} \end{equation}
$$
所以梯度$\frac{\partial\mathbf{x}^{T}\mathbf{A}\mathbf{x}}{\partial \mathbf{x}}$的第k个分量为：
$$
\begin{equation}\bigg[ \frac{\partial \mathbf{x}^{T}\mathbf{A}\mathbf{x}}{\partial \mathbf{x}} \bigg]_{k} = \frac{\partial}{\partial x_{k}} \sum_{i=1}^{n}\sum_{j=1}^{n}A_{ij}x_{i}x_{j} = \sum_{i=1}^{n}A_{ik}x_{i} + \sum_{j=1}^{n}A_{kj}x_{j} \end{equation}
$$
即有：
$$
\begin{equation}\frac{\partial \mathbf{x}^{T}\mathbf{A}\mathbf{x}}{\partial \mathbf{x}} = \mathbf{A}\mathbf{x} + \mathbf{A}^{T}\mathbf{x} \end{equation}
$$
特别的如果$\mathbf{A}$为对称矩阵则有：
$$
\begin{equation}\frac{\partial \mathbf{x}^{T}\mathbf{A}\mathbf{x}}{\partial \mathbf{x}} = 2\mathbf{A}\mathbf{x} \end{equation}
$$
归纳以上三个例子的结果以及其他结果，便得到实值函数$f(\mathbf{x})$相对于列向量$\mathbf{x}$的一下几个常用的梯度公式。

若$f(\mathbf{x}) = c$为常数，则梯度$\frac{\partial c}{\partial \mathbf{x}} = 0$

**线性法则**：若$f(\mathbf{x})$和$g(\mathbf{x})$分别是向量$\mathbf{x}$的实值函数，$c_{1}$和$c_{2}$为实常数，则：
$$
\begin{equation}\frac{\partial[c_{1}f(\mathbf{x}) + c_{2}g(\mathbf{x})]}{\partial \mathbf{x}} = c_{1}\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}} + c_{2}\frac{\partial g(\mathbf{x})}{\partial \mathbf{x}} \end{equation}
$$
**乘法法则**：若$f(\mathbf{x})$和$g(\mathbf{x})$都是向量$\mathbf{x}$的实值函数，则：
$$
\begin{equation}\frac{f(\mathbf{x})g(\mathbf{x})}{\partial \mathbf{x}} = g(\mathbf{x})\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}} + f(\mathbf{x}) \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}} \end{equation}
$$
**商法则**：若$g(\mathbf{x})\neq 0$，则：
$$
\begin{equation}\frac{\partial f(\mathbf{x})/g(\mathbf{x})}{\partial \mathbf{x}} = \frac{1}{g^{2}(\mathbf{x})}\bigg[ g(\mathbf{x})\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}} - f(\mathbf{x}) \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}} \bigg] \end{equation}
$$
**链式法则**：若$\mathbf{y}(\mathbf{x})$是$\mathbf{x}$的向量值函数，则：
$$
\begin{equation}\frac{\partial f(\mathbf{y}(\mathbf{x}))}{\partial \mathbf{x}} = \frac{\partial \mathbf{y}^{T}(\mathbf{x})}{\partial \mathbf{x}}\frac{\partial f(\mathbf{y})}{\partial \mathbf{y}} \end{equation}
$$
式中$\frac{ \partial\mathbf{y}^{T}(\mathbf{x})}{\partial \mathbf{x}}$为$n\times n$矩阵。

#### 例子

若$n\times 1$向量$\mathbf{a}$与$\mathbf{x}$是无关的常数向量，则：

$$
\begin{equation}\frac{\partial \mathbf{a}^{T}\mathbf{x}}{\partial \mathbf{x}} = \mathbf{a} \qquad \frac{\partial\mathbf{x}^{T}\mathbf{a}}{\partial \mathbf{x}} = \mathbf{a} \end{equation}
$$
若$n\times 1$向量$\mathbf{a}$与$\mathbf{x}$是无关的常数向量，则：

$$
\begin{equation}\frac{\partial\mathbf{a}^{T}\mathbf{y}(\mathbf{x})}{\partial \mathbf{x}} = \frac{\partial \mathbf{y}^{T}(\mathbf{x})}{\partial \mathbf{x}} \mathbf{a} \qquad \frac{\partial\mathbf{y}^{T}(\mathbf{x})\mathbf{a}}{\partial \mathbf{x}} =\frac{\partial\mathbf{y}^{T}(\mathbf{x})}{\partial \mathbf{x}} \mathbf{a} \end{equation}
$$

若$\mathbf{A}$和$\mathbf{y}$均与$\mathbf{x}$无关，则：

$$
\begin{equation}\frac{\partial \mathbf{x}^{T}\mathbf{A}\mathbf{y}}{\partial \mathbf{x}} = \mathbf{A}\mathbf{y} \qquad \frac{\partial \mathbf{y}^{T}\mathbf{A}\mathbf{x}}{\partial \mathbf{x}} = \mathbf{A}^{T}\mathbf{y} \end{equation}
$$

若$\mathbf{A}$是与$\mathbf{x}$无关，而$\mathbf{y}(\mathbf{x})$与向量$\mathbf{x}$的元素有关，则：

$$
\begin{equation}\frac{\partial[\mathbf{y}(\mathbf{x})]^{T} \mathbf{A}\mathbf{y}(\mathbf{x})}{\partial \mathbf{x}} = \frac{\partial[\mathbf{y}(\mathbf{x})]^{T}}{\partial \mathbf{x}}(\mathbf{A} + \mathbf{A}^{T})\mathbf{y}(\mathbf{x}) \end{equation}
$$
若$\mathbf{A}$是一个与向量$\mathbf{x}$无关的矩阵，而$\mathbf{y}(\mathbf{x})$和$\mathbf{z}(\mathbf{x})$是与向量$\mathbf{x}$的元素有关的列向量，则：

$$
\begin{equation}\frac{[\mathbf{y}(\mathbf{x})]^{T} \mathbf{A}\mathbf{z}(\mathbf{x})}{\partial \mathbf{x}} = \frac{[\mathbf{y}(\mathbf{x})]^{T}}{\partial \mathbf{x}} \mathbf{A}\mathbf{z}(\mathbf{x}) + \frac{[\mathbf{z}(\mathbf{x})]^{T}}{\partial \mathbf{x}}\mathbf{A}^{T}\mathbf{y}(\mathbf{x}) \end{equation}
$$
令$\mathbf{x}$为$n\times 1$向量，$\mathbf{a}$为$m\times 1$常数向量，$\mathbf{A}$和$\mathbf{B}$分别为$m\times n$和$m\times m$常数矩阵，且$\mathbf{B}$为对称矩阵，则：

$$
\begin{equation}\frac{\partial (\mathbf{a} - \mathbf{A} \mathbf{x})^{T}\mathbf{B}(\mathbf{a} - \mathbf{A}\mathbf{x})}{\partial \mathbf{x}} = -2\mathbf{A}^{T}\mathbf{B}(\mathbf{a} - \mathbf{A}\mathbf{x}) \end{equation}
$$
### 实值函数的梯度矩阵

在最优化问题中，需要最优化的对象可能是某个加权矩阵。因此，有必要分析实值函数相对于矩阵变元的梯度。

实值函数$f(\mathbf{A})$相对于$m\times n$是矩阵$\mathbf{A}$的梯度为$m\times n$矩阵，简称梯度矩阵，定义为：

$$
\begin{equation}\frac{\partial f(\mathbf{A})}{\partial \mathbf{A}} = \begin{bmatrix} \frac{\partial f(\mathbf{A})}{\partial A_{11}} & \frac{\partial f(\mathbf{A})}{\partial A_{12}} & \ldots \frac{\partial f(\mathbf{A})}{\partial A_{1n}} \\ \frac{\partial f(\mathbf{A})}{\partial A_{21}} & \frac{\partial f(\mathbf{A})}{\partial A_{22}} & \ldots \frac{\partial f(\mathbf{A})}{\partial A_{2n}} \\ \vdots & \vdots & \ldots & \vdots \\ \frac{\partial f(\mathbf{A})}{\partial A_{m1}} & \frac{\partial f(\mathbf{A})}{\partial A_{m2}} & \ldots \frac{\partial f(\mathbf{A})}{\partial A_{mn}} \end{bmatrix} \end{equation}
$$


式中$A_{ij}$是$\mathbf{A}$的元素。

实值函数相对于矩阵变元的梯度具有以下性质：

若$f(\mathbf{A}) = c$是常数，其中$\mathbf{A}$为$m\times n$矩阵，则梯度$\frac{\partial c}{\partial \mathbf{A}} = \mathbf{O}_{m\times n}$

**线性法则**：若$f(\mathbf{A})$和$g(\mathbf{A})$分别是矩阵$\mathbf{A}$的实值函数,$c_{1}$,$c_{2}$均为实常数，则：
$$
\begin{equation}\frac{\partial [c_{1}f(\mathbf{A}) + c_{2}g(\mathbf{A})]}{\partial \mathbf{A}} = c_{1}\frac{\partial f(\mathbf{A})}{\partial \mathbf{A}} + c_{2}\frac{\partial g(\mathbf{A})}{\partial \mathbf{A}} \end{equation}
$$

**乘积法则**：若$f(\mathbf{A})$，$g(\mathbf{A})$都是矩阵$\mathbf{A}$的实值函数，则：
$$
\begin{equation}\frac{\partial f(\mathbf{A})g(\mathbf{A})}{\partial \mathbf{A}} = f(\mathbf{A})\frac{\partial g(\mathbf{A})}{\partial \mathbf{A}} + g(\mathbf{A}) \frac{\partial f(\mathbf{A})}{\partial \mathbf{A}} \end{equation}
$$

**商法则**：若$g(\mathbf{A})\neq 0$，则：
$$
\begin{equation}\frac{\partial f(\mathbf{A})/g(\mathbf{A})}{\partial \mathbf{A}} = \frac{1}{[g(\mathbf{A})]^{2}} \bigg[ g(\mathbf{A}) \frac{\partial f(\mathbf{A})}{\partial \mathbf{A}} - f(\mathbf{A}) \frac{\partial g(\mathbf{A})}{\partial \mathbf{A}} \bigg] \end{equation}
$$



**链式法则**：令$\mathbf{A}$为$m\times n$的矩阵，且$y=f(\mathbf{A})$和$g(y)$分别是以矩阵$\mathbf{A}$和标量$y$为变元的实值函数，则：

$$
\begin{equation}\frac{\partial g(f(\mathbf{A}))}{\partial \mathbf{A}} = \frac{\mathrm{d}g(y)}{\mathrm{d} y}\frac{\partial f(\mathbf{A})}{\partial \mathbf{A}} \end{equation}
$$

#### 例子

若$\mathbf{A}\in R^{m\times n}$,$\mathbf{x}\in R^{m\times 1}$,$\mathbf{y}\in R^{n\times 1}$，则：
$$
\begin{equation}\frac{\partial \mathbf{x}^{T}\mathbf{A}\mathbf{y}}{\partial \mathbf{A}} = \mathbf{x}\mathbf{y}^{T} \end{equation}
$$


若$\mathbf{A}\in R^{n\times n}$非奇异，$\mathbf{x}\in R^{n\times 1}$,$\mathbf{y}\in R^{n\times 1}$,则：

$$
\begin{equation}\frac{\partial \mathbf{x}^{T} \mathbf{A}^{-1}\mathbf{y}}{\partial \mathbf{A}} = -\mathbf{A}^{-T}\mathbf{x}\mathbf{y}^{T}\mathbf{A}^{-T} \end{equation}
$$


若$\mathbf{A}\in R^{m\times n}$,$\mathbf{x}\in R^{n\times 1}$,$\mathbf{y}\in R^{n\times 1}$，则：
$$
\begin{equation}\frac{\partial \mathbf{x}^{T} \mathbf{A}^{T}\mathbf{A}\mathbf{y}}{\partial \mathbf{A}} = \mathbf{A}(\mathbf{x}\mathbf{y}^{T} + \mathbf{y}\mathbf{x}^{T}) \end{equation}
$$
若$\mathbf{A}\in R^{m\times n}$,$\mathbf{x}$,$\mathbf{y}\in R^{m\times 1}$，则：

$$
\begin{equation}\frac{\partial \mathbf{x}^{T}\mathbf{A}\mathbf{A}^{T}\mathbf{y}}{\partial \mathbf{A}} = (\mathbf{x}\mathbf{y}^{T} + \mathbf{y}\mathbf{x}^{T})\mathbf{A} \end{equation}
$$
指数函数的梯度：
$$
\begin{equation}\frac{\partial \exp(\mathbf{x}^{T}\mathbf{A}\mathbf{y})}{\partial \mathbf{A}} = \mathbf{x}\mathbf{y}^{T} \exp(\mathbf{x}^{T}\mathbf{A}\mathbf{y}) \end{equation}
$$

### 迹函数的梯度矩阵

有时候，二次型目标函数可以利用矩阵的迹加以重写。因为一标量可以视为$1\times 1$的矩阵，所以二次型目标函数的迹直接等同于函数本身，即$f(\mathbf{x}) = \mathbf{x}^{T}\mathbf{A}\mathbf{x} = \mathrm{tr}(\mathbf{x}^{T}\mathbf{A}\mathbf{x}) $ 利用迹的性质，又可以将目标函数进一步表示为：

$$
\begin{equation}f(\mathbf{x}) = \mathbf{x}^{T}\mathbf{A}\mathbf{x} = \mathrm{tr}(\mathbf{x}^{T}\mathbf{A}\mathbf{x}) = \mathrm{tr}(\mathbf{A}\mathbf{x}\mathbf{x}^{T}) \end{equation}
$$
因此，二次型目标函数$\mathbf{x}^{T}\mathbf{A}\mathbf{x}$等于核矩阵$\mathbf{A}$和向量外积$\mathbf{x}\mathbf{x}^{T}$的乘积的迹
$$
\mathrm{tr}(\mathbf{A}\mathbf{x}\mathbf{x}^{T})
$$


对于$n\times n$矩阵$\mathbf{A}$,由于$\mathrm{tr}(\mathbf{A}) = \sum_{i=1}^{n}A_{ii}$，故梯度$\frac{\partial \mathrm{tr}(\mathbf{A})}{\partial \mathbf{A}}$的$(i,j)$元素为：
$$
\begin{equation}\bigg[\frac{\partial \mathrm{tr}(\mathbf{A})}{\partial \mathbf{A}} \bigg]_{ij} = \frac{\partial}{\partial A_{ij}}\sum_{k=1}^{n}A_{kk} = \begin{cases} 1 & j=i \\ 0 & j\neq i \end{cases} \end{equation}
$$
所以有$\frac{\partial \mathrm{tr}(\mathbf{A})}{\partial \mathbf{A}} = \mathbf{I}$



考察目标函数$f(\mathbf{A}) = \mathrm{tr}(\mathbf{A}\mathbf{B})$，其中$\mathbf{A}$和$\mathbf{B}$分别为$m\times n$和$mn\times m$实矩阵。首先，矩阵乘积的元素为$[\mathbf{A}\mathbf{B}]_{ij} = \sum_{l=1}^{n}A_{il}B_{lj}$，故矩阵乘积的迹$\mathrm{tr}(\mathbf{A}\mathbf{B}) = \sum_{p=1}^{m}\sum_{l=1}^{n}A_{pl}B_{lp}$，于是，梯度$\frac{\partial \mathrm{tr}(\mathbf{A}\mathbf{B})}{\partial \mathbf{A}}$是一个$m\times n$矩阵，其元素为：

$$
\begin{equation}\bigg[ \frac{\partial \mathrm{tr}(\mathbf{A}\mathbf{B})}{\partial \mathbf{A}} \bigg]_{ij} = \frac{\partial }{\partial A_{ij}} \bigg(\sum_{p=1}^{m}\sum_{l=1}^{n}A_{pl}B_{lp} \bigg) = B_{ji} \end{equation}
$$
所以有:
$$
\begin{equation}\frac{\partial \mathrm{tr}(\mathbf{A}\mathrm{B})}{\partial \mathbf{A}} = \nabla_{\mathbf{A}} \mathrm{tr}(\mathbf{A}\mathrm{B}) = \mathbf{B}^{T} \end{equation}
$$
由于$\mathrm{tr}(\mathbf{B}\mathbf{A}) = \mathrm{tr}(\mathbf{A}\mathbf{B})$所以：

$$
\begin{equation}\frac{ \partial \mathrm{tr}(\mathbf{A}\mathrm{B}) }{\partial \mathbf{A}} = \frac{\partial \mathrm{tr}(\mathbf{B}\mathbf{A})}{\partial \mathbf{A}} = \mathbf{B}^{T} \end{equation}
$$
同理，由于$\mathrm{tr}(\mathbf{x}\mathbf{y}^{T}) = \mathrm{tr}(\mathbf{y}\mathbf{x}^{T}) = \mathbf{x}^{T}\mathbf{y}$，所以有：
$$
\begin{equation}\frac{\partial \mathrm{tr}(\mathbf{x}\mathbf{y}^{T})}{\partial \mathbf{x}} = \frac{\partial \mathrm{tr}(\mathbf{y}\mathbf{x}^{T})}{\partial \mathbf{x}} = \mathbf{y} \end{equation}
$$
### Hessian 矩阵

实值函数$f(\mathbf{x})$相对于$m\times 1$实向量$\mathbf{x}$的二阶偏导是一个由$m^{2}$个二阶偏导组成的矩阵，称为 Hessian 矩阵，定义为：
$$
\begin{equation}\frac{\partial^{2} f(\mathbf{x})}{\partial \mathbf{x} \partial \mathbf{x}^{T}} = \frac{\partial}{\partial \mathbf{x}^{T}} \bigg[\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}} \bigg] \end{equation}
$$
或者简写为梯度的梯度：

$$
\begin{equation}\nabla_{\mathbf{x}}^{2}f(\mathbf{x}) = \nabla_{\mathbf{x}} (\nabla_{\mathbf{x}} f(\mathbf{x})) \end{equation}
$$
根据定义,Hessian 矩阵的第j列是梯度$\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}} = \nabla_{\mathbf{x}} f(\mathbf{x})$第$j$个分量的梯度，即：
$$
\begin{equation}\bigg[ \frac{\partial^{2}f(\mathbf{x}) }{\partial \mathbf{x} \partial \mathbf{x}^{T}} \bigg]_{i,j} = \frac{\partial^{2}f(\mathbf{x})}{\partial x_{i} \partial x_{j}} \end{equation}
$$
或者可以写作：

$$
\begin{equation}\frac{\partial^{2} f(\mathbf{x})}{\partial \mathbf{x} \partial \mathbf{x}^{T}} = \begin{bmatrix} \frac{\partial^{2}f}{\partial x_{1}\partial x_{1}} & \frac{\partial^{2}f}{\partial x_{1}\partial x_{2}} & \ldots & \frac{\partial^{2}f}{\partial x_{1}\partial x_{n}} \\ \frac{\partial^{2}f}{\partial x_{2}\partial x_{1}} & \frac{\partial^{2}f}{\partial x_{2}\partial x_{2}} & \ldots & \frac{\partial^{2}f}{\partial x_{2}\partial x_{n}} \\ \vdots & \vdots & \ddots & \vdots \\ \frac{\partial^{2}f}{\partial x_{n}\partial x_{1}} & \frac{\partial^{2}f}{\partial x_{n}\partial x_{2}} & \ldots & \frac{\partial^{2}f}{\partial x_{n}\partial x_{n}} \\ \end{bmatrix} \end{equation}
$$
因此，Hessian 矩阵可以通过两个步骤计算得出：

1. 求实值函数$f(\mathbf{x})$关于向量变元$\mathbf{x}$的偏导数，得到实值函数的梯度$\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}$
2. 再求梯度$\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}$相对于$1\times n$行向量\mathbf{x}^{T}的偏导数，得到梯度的梯度即 Hessian 矩阵

根据以上步骤，得到 Hessian 矩阵的下列公式。

对于$n\times 1$的常数向量$\mathbf{a}^{T}$，有：
$$
\begin{equation}\frac{\partial^{2} \mathbf{a}^{T}\mathbf{x}}{\partial \mathbf{x}\partial \mathbf{x}^{T}} = \mathbf{O}_{n\times n} \end{equation}
$$
若$\mathbf{A}$是$n\times n$矩阵，则：

$$
\begin{equation}\frac{\partial^{2} \mathbf{x}^{T}\mathbf{A}\mathbf{x}}{\partial \mathbf{x}\partial \mathbf{x}^{T}} = \mathbf{A} + \mathbf{A}^{T} \end{equation}
$$
令$\mathbf{x}$为$n\times 1$向量，$\mathbf{a}$为$m\times 1$常数向量，$\mathbf{A}$和$\mathbf{B}$分别为$m\times n$和$m\times m$常数矩阵，且$\mathbf{B}$为对称矩阵，则：
$$
\begin{equation}\frac{\partial^{2}(\mathbf{a} - \mathbf{A}\mathbf{x})^{T}\mathbf{B} (\mathbf{a} - \mathbf{A}\mathbf{x}) }{\partial \mathbf{x} \partial \mathbf{x}^{T}} = 2\mathbf{A}^{T}\mathbf{B}\mathbf{A} \end{equation}
$$




### 利用全微分求导

**矩阵的迹** tr(A)与一阶实矩阵微分dX
$$
A = \left[ {\left. {\begin{array}{*{20}{c}}
  {{a_{11}}}&{{a_{12}}}&{...}&{{a_{1n}}} \\ 
  {{a_{21}}}&{{a_{22}}}&{...}&{{a_{2n}}} \\ 
  {...}&{...}&{...}&{...} \\ 
  {{a_{n1}}}&{{a_{n2}}}&{...}&{{a_{nn}}} 
\end{array}} \right]} \right.
$$

矩阵的迹：$tr(A) = {a_{11}} + {a_{22}} +  \cdot  \cdot  \cdot  + {a_{n}} = \sum\limits_{i = 1}^n {{a_{ii}}}$

只有**方阵**才有迹

交换律：$tr(AB) = tr(BA),{A_{m \times n}},{B_{n \times m}}$

**矩阵变元**的**实值标量函数**的**全微分**：$df(X) = tr(\frac{{\partial f(X)}}{{\partial {X^T}}}dX)$

矩阵变元或向量变元的实值标量函数的**矩阵求导**的结果，都可以通过上式求解

使用**矩阵微分**求导：

对于实值标量函数$f(X),tr(f(X))=f(X),df(X)=tr(df(X))$,所以有$df(X)=tr(df(X))=d(trf(X))$

如果实值标量函数本身就是某个**矩阵函数**${F_{p \times p}}(X)$的迹，如$reF(X)$，则由全微分的线性法则得：
$$
d(tr{F_{p \times p}}(X)) = d(\sum\limits_{i = 1}^p {{f_{ii}}(X)} ) = \sum\limits_{i = 1}^p {d({f_{ii}}(X)) = tr(d{F_{p \times p}}(X))}
$$

### 常见的求导

- $\frac{{\partial ({x^T}a)}}{{\partial x}} = \frac{{\partial ({a^T}x)}}{{\partial x}} = a$
- $\frac{{\partial ({x^T}x)}}{{\partial x}} = 2x$
- $\frac{{\partial ({x^T}Ax)}}{{\partial x}} = Ax + {A^T}x,{A_{n \times n}} = ({a_{ij}})_{i = 1,j = 1}^{n,n}$
- $\frac{{\partial ({a^T}x{x^T}b)}}{{\partial x}} = a{b^T}x + b{a^T}x,a = {({a_1},{a_2},...,{a_n})^T},b = {({b_1},{b_2},...,{b_n})^T}$
- $\frac{{\partial ({a^T}xb)}}{{\partial x}} = a{b^T},{a_{m \times 1}},{b_{n \times 1}},{x_{m \times n}}$
- $\frac{{\partial ({a^T}{x^T}b)}}{{\partial x}} = b{a^T},{a_{m \times 1}},{b_{n \times 1}},{x_{m \times n}}$
- $\frac{{\partial ({a^T}x{x^T}b)}}{{\partial x}} = a{b^T}x + b{a^T}x,{a_{m \times 1}},{b_{m \times 1}},{x_{m \times m}}$
- $\frac{{\partial ({a^T}{x^T}xb)}}{{\partial x}} = xa{b^T} + xb{a^T},{a_{m \times 1}},{b_{m \times 1}},{x_{m \times m}}$

#### 常用的结论：

证明：$d\left| X \right| = \left| X \right|tr({X^{ - 1}}dX)$
$$
\begin{gathered}
  \left| X \right| = {x_{i1}}{A_{i1}} + {x_{i2}}{A_{i2}} + ... + {x_{in}}{A_{in}} \hfill \\
  \frac{{\partial \left| X \right|}}{{\partial {x_{ij}}}} = {A_{ij}} \hfill \\
  \frac{{\partial \left| X \right|}}{{\partial {X^T}}} = \left[ {\left. {\begin{array}{*{20}{c}}
  {{A_{11}}}&{{A_{21}}}&{...}&{{A_{n1}}} \\ 
  {{A_{12}}}&{{A_{22}}}&{...}&{{A_{n2}}} \\ 
  {...}&{...}&{...}&{...} \\ 

  {{A_{1n}}}&{{A_{2n}}}&{...}&{{A_{nn}}} 
\end{array}} \right]} \right. = {X^*} = \left| X \right|{X^{ - 1}} \hfill \\
  d\left| X \right| = tr(\frac{{\partial \left| X \right|}}{{\partial {X^T}}}dX) = tr(\left| X \right|{X^{ - 1}}dX) \hfill \\ 
\end{gathered}
$$
$d({X^{ - 1}}) =  - {X^{ - 1}}dX({X^{ - 1}})$

